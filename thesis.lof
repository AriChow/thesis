\contentsline {figure}{\numberline {1.1}{\ignorespaces Representation of an image classification pipeline.\relax }}{2}{figure.caption.10}
\contentsline {figure}{\numberline {2.1}{\ignorespaces Reducing classification error by modifying algorithms from the image pre-processing layer of the image classification pipeline. The step highlighted in red is modified for reducing the out of sample error.\relax }}{6}{figure.caption.11}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Depiction of the different morphologies in the natural data with respect to a multichannel image, overlaid with different protein markers. The blue and red channels represent the cell nuclei and neurons respectively. The three types of morphologies analyzed in this study is represented on the right.\relax }}{8}{figure.caption.12}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Development of the 3D virtual model.\relax }}{10}{figure.caption.13}
\contentsline {figure}{\numberline {2.4}{\ignorespaces 3D virtual models and their corresponding projections along different planes of view (a) Linear model of \textit {RoundLumen-} (b) Linear model of \textit {RoundLumen+} (c) Non-linear model of \textit {RoundLumen+} (d) Non-linear model of \textit {Twins}.\relax }}{10}{figure.caption.14}
\contentsline {figure}{\numberline {2.5}{\ignorespaces The CNN architecture (\textit {AlexNet}) used in this work.\relax }}{12}{figure.caption.15}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Examples of vessel classes \textit {RoundLumen-} (a/d), \textit {RoundLumen+} (b/e) and \textit {Twins} (c/f) for natural (a/b/c) and virtual data (d/e/f).\relax }}{13}{figure.caption.16}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Plots of the receiver operating characteristics (ROC) curve and the precision recall (PR) curve of the classification between \textit {RoundLumen} and \textit {Twins} along with the area under the curves (AUC) for the three experiments denoted as legends in the plots. From the nature of the curves, and the values of the AUC, we conclude that combining the using \textit {mixed} data performs better than using the \textit {Natural} data or the \textit {Artificial data} in isolation.\relax }}{14}{figure.caption.17}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Plots of the receiver operating characteristics (ROC) curve and the precision recall (PR) curve of the classification between \textit {RoundLumen+} and \textit {RoundLumen-} along with the area under the curves (AUC) for the three experiments denoted as legends in the plots. From the nature of the curves, and the values of the AUC, we conclude that combining the using \textit {mixed} data performs better than using the \textit {Natural} data or the \textit {Artificial data} in isolation.\relax }}{15}{figure.caption.18}
\contentsline {figure}{\numberline {3.1}{\ignorespaces Reducing classification error by optimizing the components of the image classification pipeline together instead of in isolation. The steps in the image classification pipeline highlighted in red are optimized simultaneously to minimize the classification error.\relax }}{18}{figure.caption.19}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Examples of micrographs used in classification. Micrographs shown in (a) and (b) are longitudinal and transverse cross-sectional views of dendrites, whereas micrographs in (c) do not contain dendrites. Micrographs in (a), (b) and (c) were used in Task 1, and micrographs in (a) and (b) were used in Task 2.\relax }}{21}{figure.caption.20}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Overview of approach used in classification of micrograph data. The approach summarized here shows 140 different combinations of feature extraction, feature selection and classification methods completed. The same approach presented here was completed first for Task 1 (Data Set 1), then for Task 2 (Data Set 2).\relax }}{23}{figure.caption.21}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Top 20 configurations of algorithms in Task 1 with error bars representing one standard deviation. There is no significant difference in the accuracies in the different configuations. Most of the feature extraction algorithms in the top 20 configurations are pre-trained CNNs (\textit {caffe-fc6} or \textit {caffe-conv5}).\relax }}{37}{figure.caption.22}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Top 20 configurations of algorithms in Task 2 with error bars representing one standard deviation. There is no significant difference in the accuracies in the different configuations. Most of the feature extraction algorithms in the top 20 configurations are pre-trained CNNs (\textit {caffe-fc6} or \textit {caffe-conv5}).\relax }}{41}{figure.caption.23}
\contentsline {figure}{\numberline {4.1}{\ignorespaces Quantification of the quality of the image or image datasets. In this chapter, we quantify the quality or the contribution of the image or images in the dataset used for image classification. This layer is highlighted as red in the figure.\relax }}{46}{figure.caption.24}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Examples of a single colon tumor tissue sample stained with three different markers. E\_cad is the least noisy with respect to undesirable artefacts, followed by pck26 and CK15 respectively.\relax }}{47}{figure.caption.25}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Examples of \textit {good}, \textit {bad} and \textit {ugly} images based on the \textit {QoI} score.\relax }}{50}{figure.caption.26}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Distribution of \textit {QoI} scores on the images. According to the pathologist, the perceived quality of the images from the E\_cad and pck26 marker is good and the images from the CK15 marker has low signal and high noise in general. This is reflected in the distribution of these markers.\relax }}{51}{figure.caption.27}
\contentsline {figure}{\numberline {5.1}{\ignorespaces Quantification of error contributions from different components of the pipeline. Similar to chapter \ref {chap:COMMAT}, the feature extraction, feature transformation and learning algorithms are highlighted in red. In this chapter we use the feedback from the validation error to quantify the contribution of each of the components of the pipeline.\relax }}{55}{figure.caption.28}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Representation of a data analysis pipeline. This is represented as a generalized directed acyclic graph. $S_i$ represents the $i$-th computational step in the pipeline and $A_{ij}$ represents the $j$-th algorithm in the $i$-th step. $X$ is the input dataset and $Y$ is the evaluation metric.\relax }}{56}{figure.caption.29}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Optimization frameworks.\relax }}{59}{figure.caption.30}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Representation of the image classification pipeline as a directed acyclic graph used in this work. This is an instantiation of the generalized data analytic pipeline in Fig. \ref {fig:pipeline}.\relax }}{64}{figure.caption.31}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Plots of error contributions from computational steps in the pipeline. The x-axis represents the steps in the pipeline - feature extraction, feature transformation and learning algorithms. The y-axis shows the values of the contributions from the corresponding steps in the pipeline. The maximum contribution in terms of error is from the feature extraction step in the pipeline. Random search (blue) follows the behavior of grid search (red) more accurately than Bayesian optimization (yellow). Hence, random search maybe used to quantify the error contributions instead of grid search.\relax }}{68}{figure.caption.32}
\contentsline {figure}{\numberline {5.6}{\ignorespaces Plots of error contributions from algorithms in the pipeline. The x-axis represents the algorithms in the path - \textit {haralick texture features}, $PCA$ and \textit {random forests}. The y-axis shows the values of the contributions from the corresponding algorithms in the path. Random search again mirrors the trend of grid search more than bayesian optimization. Therefore random search maybe used instead of grid search for computing the contribution of error from algorithms in a path. The plots also show that it is more important to tune \textit {haralick texture features}, and \textit {random forests} than it is to tune $PCA$. \relax }}{70}{figure.caption.33}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Plots of error contributions from hyperparameters in the pipeline. The x-axis represents the algorithms in the path - \textit {Haralick distance}, \textit {whitening}, \textit {Number of estimators} and \textit {Maximum features}. The y-axis shows the values of the contributions from the corresponding hyperparameters in the path. Random search again mirrors the trend of grid search more than bayesian optimization. Therefore random search maybe used instead of grid search for computing the contribution of error from hyperparameters in a path. The plots also show that it is more important to tune the hyperparameters \textit {Haralick distance}, and \textit {Number of estimators} than it is to tune the other hyperparameters.\relax }}{71}{figure.caption.34}
\contentsline {figure}{\numberline {5.8}{\ignorespaces Comparison of computational time for running each of the 3 optimization methods in the two optimization frameworks (HPO and CASH) in section \ref {subsec_AS_HPO} averaged over the 4 datasets in Table \ref {table:datasets}. Random search and bayesian optimization are both much more efficient that grid search in terms of computation time and maybe used to quantify the error contribution more efficiently than grid search.\relax }}{72}{figure.caption.35}
\contentsline {figure}{\numberline {5.9}{\ignorespaces Front-end of the application that shows the interactive screens of the CIR. The first screen from the left shows the actions taken by the experts in the room, and the list of algorithms in the pipeline, The second screen shows a module where the experts may interact with the CIR. The third screen shows the dialogue among the experts and the results of the analysis. The right most screen shows how the error contribution results maybe used by domain experts and data scientists in the room to solve the problem of breast cancer diagnosis.\relax }}{73}{figure.caption.36}
\contentsline {figure}{\numberline {5.10}{\ignorespaces Example of an application of the error contribution framework. This figure shows a demonstration of the CIR using a panoramic display for the use case of breast cancer diagnosis. The front-end of the display is depicted in Fig. \ref {fig:CISL}.\relax }}{73}{figure.caption.37}
