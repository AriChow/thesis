\contentsline {figure}{\numberline {1.1}{\ignorespaces Representation of an image classification pipeline\relax }}{2}{figure.caption.10}
\contentsline {figure}{\numberline {2.1}{\ignorespaces Examples of micrographs used in classification. Micrographs shown in (a) and (b) are longitudinal and transverse cross-sectional views of dendrites, whereas micrographs in (c) do not contain dendrites. Micrographs in (a), (b) and (c) were used in Task 1, and micrographs in (a) and (b) were used in Task 2.\relax }}{9}{figure.caption.11}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Overview of approach used in classification of micrograph data. The approach summarized here shows 140 different combinations of feature extraction, feature selection and classification methods completed. The same approach presented here was completed first for Task 1 (Data Set 1), then for Task 2 (Data Set 2).\relax }}{10}{figure.caption.12}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Top 20 configurations of algorithms in Task 1 with error bars representing one standard deviation. There is no significant difference in the accuracies in the different configuations. Most of the feature extraction algorithms in the top 20 configurations are pre-trained CNNs (\textit {caffe-fc6} or \textit {caffe-conv5})\relax }}{24}{figure.caption.13}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Top 20 configurations of algorithms in Task 2 with error bars representing one standard deviation. There is no significant difference in the accuracies in the different configuations. Most of the feature extraction algorithms in the top 20 configurations are pre-trained CNNs (\textit {caffe-fc6} or \textit {caffe-conv5})\relax }}{28}{figure.caption.14}
\contentsline {figure}{\numberline {3.1}{\ignorespaces Depiction of the different morphologies in the natural data with respect to a multichannel image, overlaid with different protein markers. The three types of morphologies analyzed in this study is represented on the right.\relax }}{34}{figure.caption.16}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Development of the 3D virtual model\relax }}{36}{figure.caption.17}
\contentsline {figure}{\numberline {3.3}{\ignorespaces 3D virtual models and their corresponding projections along different planes of view (a) Linear model of \textit {RoundLumen-} (b) Linear model of \textit {RoundLumen+} (c) Non-linear model of \textit {RoundLumen+} (d) Non-linear model of \textit {Twins}\relax }}{36}{figure.caption.18}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Examples of vessel classes \textit {RoundLumen-} (a/d), \textit {RoundLumen+} (b/e) and \textit {Twins} (c/f) for natural (a/b/c) and virtual data (d/e/f)\relax }}{39}{figure.caption.19}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Plots of the receiver operating characteristics (ROC) curve and the precision recall (PR) curve of the classification between \textit {RoundLumen} and \textit {Twins} along with the area under the curves (AUC) for the three experiments denoted as legends in the plots. From the nature of the curves, and the values of the AUC, we conclude that combining the using \textit {mixed} data performs better than using the \textit {Natural} data or the \textit {Artificial data} in isolation.\relax }}{40}{figure.caption.20}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Plots of the receiver operating characteristics (ROC) curve and the precision recall (PR) curve of the classification between \textit {RoundLumen+} and \textit {RoundLumen-} along with the area under the curves (AUC) for the three experiments denoted as legends in the plots. From the nature of the curves, and the values of the AUC, we conclude that combining the using \textit {mixed} data performs better than using the \textit {Natural} data or the \textit {Artificial data} in isolation.\relax }}{41}{figure.caption.21}
\contentsline {figure}{\numberline {4.1}{\ignorespaces Examples of a single colon tumor tissue sample stained with three different markers. E\_cad is the least noisy with respect to undesirable artefacts, followed by pck26 and CK15 respectively.\relax }}{43}{figure.caption.22}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Examples of \textit {good}, \textit {bad} and \textit {ugly} images based on the \textit {QoI} score.\relax }}{46}{figure.caption.23}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Distribution of \textit {QoI} scores on the images. According to the pathologist, the perceived quality of the images from the E\_cad and pck26 marker is good and the images from the CK15 marker has low signal and high noise in general. This is reflected in the distribution of these markers\relax }}{47}{figure.caption.24}
\contentsline {figure}{\numberline {5.1}{\ignorespaces Representation of a machine learning pipeline. This is represented as a generalized directed acyclic graph. $S_i$ represents the $i$-th computational step in the pipeline and $A_{ij}$ represents the $j$-th algorithm in the $i$-th step. $X$ is the input dataset and $Y$ is the evaluation metric.\relax }}{51}{figure.caption.25}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Representation of an image classification pipeline. The pipeline consists of the steps represented by green ellipses and the outputs of each step represented by blue rectangles. In this work, we focus on the steps and outputs after pre-processing.\relax }}{59}{figure.caption.26}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Representation of the image classification pipeline as a directed acyclic graph used in this work. This is an instantiation of the generalized data analytic pipeline in Fig. \ref {fig:pipeline}\relax }}{60}{figure.caption.27}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Combined algorithm selection and hyper-parameter optimization in a data analytic pipeline. The algorithms and corresponding hyper-parameters are optimized simultaneously.\relax }}{62}{figure.caption.28}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Hyper-parameter optimization in a data analytic pipeline. Each path in the pipeline is individually optimized.\relax }}{62}{figure.caption.29}
\contentsline {figure}{\numberline {5.6}{\ignorespaces Plots of error contributions from computational steps in the pipeline. Random search (blue) follows the behavior of grid search (red) more accurately than Bayesian optimization (yellow). Hence, random search maybe used to quantify the error contributions instead of grid search.\relax }}{65}{figure.caption.30}
\contentsline {figure}{\numberline {5.7}{\ignorespaces Plots of error contributions from algorithms in the pipeline. Random search again mirrors the trend of grid search more than bayesian optimization. Therefore random search maybe used instead of grid search for computing the contribution of error from algorithms in a path. The plots also show that it is more important to tune \textit {haralick texture features}, and \textit {random forests} than it is to tune $PCA$. \relax }}{67}{figure.caption.31}
\contentsline {figure}{\numberline {5.8}{\ignorespaces Plots of error contributions from hyper-parameters in the pipeline. Random search again mirrors the trend of grid search more than bayesian optimization. Therefore random search maybe used instead of grid search for computing the contribution of error from hyper-parameters in a path. The plots also show that it is more important to tune the hyper-parameters \textit {Haralick distance}, and \textit {Number of estimators} than it is to tune the other hyper-parameters.\relax }}{68}{figure.caption.32}
\contentsline {figure}{\numberline {5.9}{\ignorespaces Comparison of computational time for running each of the 3 optimization methods in the two optimization frameworks (HPO and CASH) in section \ref {subsec_AS_HPO} averaged over the 4 datasets in Table \ref {table:datasets}. Random search and bayesian optimization are both much more efficient that grid search in terms of computation time and maybe used to quantify the error contribution more efficiently than grid search.\relax }}{68}{figure.caption.33}
